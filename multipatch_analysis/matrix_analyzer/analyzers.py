# -*- coding: utf-8 -*-

"""
Prototype code for analyzing connectivity and synaptic properties between cell classes.


"""
from __future__ import print_function, division

from collections import OrderedDict
import numpy as np
import pyqtgraph as pg
import pandas as pd
from statsmodels.stats.proportion import proportion_confint
from multipatch_analysis.database import default_db as db
# from first_pulse_deconvolved_amps import get_deconvolved_first_pulse_amps
from neuroanalysis.data import TSeries, TSeriesList
from neuroanalysis.baseline import float_mode


thermal_colormap = pg.ColorMap(
                    [0, 0.3333, 0.6666, 1],
                    [(255, 255, 255, 255), (255, 220, 0, 255), (185, 0, 0, 255), (0, 0, 0, 255)],
            )

class FormattableNumber(float):

    @property
    def si_format(self):
        return pg.siFormat(self)
       
    # all of the below formats assume that the number is entered with no scaling and in the form (scale)(unit)
    @property
    def mV(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e3
            formatted_value = ("%0.2f mV" % value)
        return formatted_value

    @property
    def uV(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e6
            formatted_value = (u"%0.f μV" % value)
        return formatted_value

    @property
    def pA(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e12
            formatted_value = ("%0.2f pA" % value)
        return formatted_value

    @property
    def ms(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e3
            formatted_value = ("%0.2f ms" % value)
        return formatted_value

    @property
    def us(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e6
            formatted_value = ("%0.2f μs" % value)
        return formatted_value

    @property
    def mm(self):
        if np.isnan(self):
            formatted_value = ''
        else:
            value = self*1e3
            formatted_value = ("%0.2f mm" % value)
        return formatted_value

class Analyzer(pg.QtCore.QObject):

    sigOutputChanged = pg.QtCore.Signal(object)

    def group_result(self, pair_groups):
        if self.group_results is not None:
            return self.group_results

        ## create a MultiIndex so that group_results will have the same structure as when it was generated by results.groupby
        pre_types = set()
        post_types = set()
        for pair_class in pair_groups.keys():
            pre, post = pair_class
            pre_types.add(pre)
            post_types.add(post)
        index = pd.MultiIndex.from_product([pre_types, post_types], names=['pre_class', 'post_class'])

        group_results = None
        for pair_class, pair_group in pair_groups.items():
            if len(pair_group) == 0:
                continue
            res = self.results.loc[pair_group]
            res['extra'] = [0]*len(res.index) ## create an extra column to group by.
            result = res.groupby(['extra']).agg(self.summary_stat) 

            if group_results is None:
                group_results = pd.DataFrame(result, index=index)
                #dtype_dict = {}
                #for i in range(len(result.columns)):
                #    dtype_dict[result.columns[i]] = result.dtypes[result.columns[i]]

            pre_class, post_class = pair_class
            group_results.loc[pre_class, post_class] = result.iloc[0]

        ### filter out all the pair_groups we don't have data for. (To be consistent with results from .groupby)
        nan_indices = group_results.loc[group_results.isnull().all(axis=1), :].index.tolist()
        for i in nan_indices:
            group_results = group_results.drop(i)

        group_results = group_results.astype(self.summary_dtypes)

        self.group_results = group_results
        return self.group_results




class ConnectivityAnalyzer(Analyzer):

    def __init__(self, analyzer_mode):
        Analyzer.__init__(self)
        self.name = 'connectivity'
        self.results = None
        self.group_results = None
        #self._signalHandler = ConnectivityAnalyzer.SignalHandler()
        #self.sigOutputChanged = self._signalHandler.sigOutputChanged

        self.fields = [
            ('Probed Connection', {}),
            ('Synapse', {}),
            ('Gap Junction', {}),
            ('Distance', {'mode': 'range', 'units': 'm', 'defaults': {
                'Max': 200e-6,
                'colormap': pg.ColorMap(
                    [0, 0.25, 0.5, 0.75, 1.0],
                    [(255,255,100,255), (255,100,0,255), (0,0,100,255), (140,0,0,255), (80,0,80,255)],
            )}}),
            ('Synapse Probability', {'mode': 'range', 'defaults': {
                'Operation': 'Add', 
                'colormap': pg.ColorMap(
                [0, 0.01, 0.03, 0.1, 0.3, 1.0],
                [(0,0,100, 255), (80,0,80, 255), (140,0,0, 255), (255,100,0, 255), (255,255,100, 255), (255,255,255, 255)],
            )}}),
            ('Gap Junction Probability', {'mode': 'range', 'defaults': {
                'colormap': pg.ColorMap(
                   [0, 0.01, 0.03, 0.1, 0.3, 1.0],
                    [(0,0,100, 255), (80,0,80, 255), (140,0,0, 255), (255,100,0, 255), (255,255,100, 255), (255,255,255, 255)],
            )}}),
            ('None', {}),
            ]

        if analyzer_mode == 'internal':
            self.fields.append(
                ('matrix_completeness', {'mode': 'range', 'defaults': {
                'colormap': pg.ColorMap(
                    [0, 0.25, 0.5, 0.75, 1.0],
                    [(0,0,100,255), (80,0,80,255), (140,0,0,255), (255,100,0,255), (255,255,100,255)],
            )}}))

        self.summary_stat = {
            'conn_no_data': self.metric_summary,
            'Probed Connection': self.metric_summary,
            'Synapse': self.metric_summary,
            'Gap Junction': [self.metric_summary, self.metric_conf],
            'Synapse Probability': [self.metric_summary, self.metric_conf],
            'Gap Junction Probability': [self.metric_summary, self.metric_conf],
            'matrix_completeness': [self.metric_summary, self.metric_conf],
            'Distance': [self.metric_summary, self.metric_conf],
        }
        self.summary_dtypes = {
            ('conn_no_data', 'metric_summary'): bool,
            ('Probed Connection', 'metric_summary'): int,
            ('Synapse', 'metric_summary'): int,
            ('Gap Junction', 'metric_summary'):int,
        }

        self.text = {
            'Probed Connection': '{Probed Connection}',
            'Synapse': '{Synapse}',
            'Gap Junction': '{Gap Junction}',
            'Synapse Probability': '{Synapse}/{Probed Connection}',
            'Gap Junction Probability': '{Gap Junction}/{Probed Connection}',
            'matrix_completeness': '{Synapse}/{Probed Connection}',
            'Distance': '{Distance.mm}',
        }

    def metric_summary(self, x): 
        if x.name == 'conn_no_data':
            return all(x)
        if x.name == 'Distance':
            return np.nanmean(x)
        if x.name in ['Synapse', 'Probed Connection', 'Gap Junction']:
            #print("+++ metric_summary: ", x.name)
            #print(x)
            #print(type(x))
            return sum(filter(None, x))
        else:
            p = x.apply(pd.Series)
            p1 = p.sum()
            connected = float(p1[0])
            probed = float(p1[1])

            if x.name == 'matrix_completeness':
                probed_progress = probed/80
                connected_progress = connected/6
                return np.clip(np.where(probed_progress > connected_progress, probed_progress, connected_progress), 0, 1)
            elif x.name.endswith('Probability'):
                if probed == 0.:
                    return float('nan')
                else:
                    return connected/probed       

    def metric_conf(self, x):
        if x.name.endswith('Probability'):
            p = x.apply(pd.Series)
            p1 = p.sum()
            connected = float(p1[0])
            probed = float(p1[1])
            return connection_probability_ci(connected, probed)
        if x.name == 'Distance':
            return [-np.nanstd(x), np.nanstd(x)]
        else:
            return float('nan')
    
    def invalidate_output(self):
        self.results = None
        self.group_results = None

    def measure(self, pair_groups):
        """Given a list of cell pairs and a dict that groups cells together by class,
        return a structure that describes connectivity of each cell pair.
        """    
        if self.results is not None:
            return self.results

        results = OrderedDict()

        for key, class_pairs in pair_groups.items():
            pre_class, post_class = key
            for pair in class_pairs:
                no_data = False
                probed = pair_was_probed(pair, pre_class.is_excitatory)
                if probed is False:
                    no_data = True

                connected = pair.has_synapse if probed is True else False
                gap = pair.has_electrical if probed is True else False
                distance = pair.distance if probed is True else float('nan')
                

                results[pair] = {
                'conn_no_data': no_data,
                'pre_class': pre_class,
                'post_class': post_class,
                'Probed Connection': probed,
                'Synapse': connected,
                'Gap Junction': gap,
                'Distance': distance,
                'Synapse Probability': [int(connected) if connected is not None else 0, int(probed) if probed is not None else 0],
                'Gap Junction Probability': [int(gap) if gap is not None else 0, int(probed) if probed is not None else 0],
                'matrix_completeness': [int(connected) if connected is not None else 0, int(probed) if probed is not None else 0],
                
                }

        self.results = pd.DataFrame.from_dict(results, orient='index')

        return self.results

    def output_fields(self):

        return self.fields

    def print_element_info(self, pre_class, post_class, element, field_name):
        connections = element[element['Synapse'] == True].index.tolist()
        print ("Connection type: %s -> %s" % (pre_class, post_class))
        print ("Synaptically Connected Pairs:")
        for connection in connections:
            print ("\t %s" % (connection))
        gap_junctions = element[element['Gap Junction'] == True].index.tolist()
        print ("Gap Junctions:")
        for gap in gap_junctions:
            print ("\t %s" % (gap))
        probed_pairs = element[element['Probed Connection'] == True].index.tolist()
        print ("Probed Pairs:")
        for probed in probed_pairs:
            print ("\t %s" % (probed))
        
    def plot_element_data(self, pre_class, post_class, element, field_name, color='g', trace_plt=None):
        summary = element.agg(self.summary_stat)  
        val = summary[field_name]['metric_summary']
        line = pg.InfiniteLine(val, pen={'color': color, 'width': 2}, movable=False)
        scatter = None
        baseline_window = int(db.default_sample_rate * 5e-3)
        traces = []
        point_data = []
        connections = element[element['Synapse'] == True].index.tolist()
        for pair in connections:
            rsf = pair.resting_state_fit
            if rsf is not None:
                trace = rsf.ic_avg_data
                start_time = rsf.ic_avg_data_start_time
                latency = pair.synapse.latency
                if latency is not None and start_time is not None:
                    xoffset = start_time - latency
                    trace = format_trace(trace, baseline_window, x_offset=xoffset, align='psp')
                    trace_plt.plot(trace.time_values, trace.data)
                    traces.append(trace)
        if len(traces) > 0:
            grand_trace = TSeriesList(traces).mean()
            name = ('%s->%s, n=%d' % (pre_class, post_class, len(traces)))
            trace_plt.plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3}, name=name)
            trace_plt.setXRange(-5e-3, 20e-3)
            trace_plt.setLabels(left=('', 'V'), bottom=('Time from stimulus', 's'))
        return line, scatter

    def summary(self, ):
        total_connected = self.results['Synapse'].sum()
        total_probed = self.results['Probed Connection'].sum()
        print ("Total connected / probed\t %d / %d" % (total_connected, total_probed))

        # if metric == 'matrix_completeness':
        #     total_progress = 0
        #     for connectivity in results.values():
        #         total_progress += connectivity['matrix_completeness']
        #     n_elements = len([element for element in results.values() if element['no_data'] is False])

        #     print ("Total progress\t %0.1f%%, %d elements" % (100*total_progress/n_elements, n_elements))



class StrengthAnalyzer(Analyzer):

    def __init__(self):
        Analyzer.__init__(self)
        self.name = 'strength'
        self.results = None
        self.group_results = None
        self.pair_items = {}
        #self._signalHandler = ConnectivityAnalyzer.SignalHandler()
        #self.sigOutputChanged = self._signalHandler.sigOutputChanged

        self.summary_stat = {
        'PSP Amplitude': [self.metric_summary, self.metric_conf],
        'Latency': [self.metric_summary, self.metric_conf],
        'PSP Rise Time': [self.metric_summary, self.metric_conf],
        'PSP Decay Tau': [self.metric_summary, self.metric_conf],
        'PSC Amplitude': [self.metric_summary, self.metric_conf],
        'PSC Rise Time': [self.metric_summary, self.metric_conf],
        'PSC Decay Tau': [self.metric_summary, self.metric_conf],
        'strength_no_data': self.metric_summary,
        }
        self.summary_dtypes = {} ## dict to specify how we want to cast different summary measures
        ## looks like {('ic_fit_amp_all', 'metric_summary'):float}

        self.fields = [
            # all pulses
            ('PSP Amplitude', {'mode': 'range', 'units': 'V', 'defaults': {
                'Min': -1e-3, 
                'Max': 1e-3, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (255, 255, 255, 255), (255, 0, 0, 255)],
            )}}),
            ('PSC Amplitude', {'mode': 'range', 'units': 'A', 'defaults': {
                'Min': -20e-12, 
                'Max': 20e-12, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(255, 0, 0, 255), (255, 255, 255, 255), (0, 0, 255, 255)],
            )}}),
            ('PSP Rise Time', {'mode': 'range', 'units': 's', 'defaults': {
                'Min': 1e-3, 
                'Max': 10e-3,
                'colormap': thermal_colormap,
            }}),
            ('PSC Rise Time', {'mode': 'range', 'units': 's', 'defaults': {
                'Min': 0.5e-3, 
                'Max': 5e-3,
                'colormap': thermal_colormap,
            }}),
            ('PSP Decay Tau', {'mode': 'range', 'units': 's', 'defaults': {
                'Max': 500e-3,
                'colormap': thermal_colormap,
            }}),
            ('PSC Decay Tau', {'mode': 'range', 'units': 's', 'defaults': {
                'Max': 20e-3,
                'colormap': thermal_colormap,
            }}),
            ('Latency', {'mode': 'range', 'units': 's', 'defaults': {
                'Min': 0.5e-3, 
                'Max': 4e-3,
                'colormap': thermal_colormap,
            }}),
            ('None',{}),
        ]

        self.text = {
            'PSP Amplitude': '{PSP Amplitude.mV}',
            'PSC Amplitude': '{PSC Amplitude.pA}',
            'Latency': '{Latency.ms}',
            'PSP Rise Time': '{PSP Rise Time.ms}',
            'PSP Decay Tau': '{PSP Decay Tau.ms}',
            'PSC Rise Time': '{PSC Rise Time.ms}',
            'PSC Decay Tau': '{PSC Decay Tau.ms}',
        }

    def invalidate_output(self):
        self.results = None
        self.group_results = None
        self.pair_items = {}

    def measure(self, pair_groups):
        """Given a list of cell pairs and a dict that groups cells together by class,
        return a structure that describes strength and kinetics of each cell pair.
        """  
        if self.results is not None:
            return self.results

        results = OrderedDict()
        
        for key, class_pairs in pair_groups.items():
            pre_class, post_class = key

            for pair in class_pairs:
                if pair.has_synapse is not True:
                    no_data = True
                elif pair.has_synapse is True:
                    no_data = False
                    synapse = pair.synapse
                    if synapse is None:
                        no_data = True
                    else:
                        psp_amp = synapse.psp_amplitude
                        psp_decay_tau = synapse.psp_decay_tau
                        psp_rise_time = synapse.psp_rise_time 
                        psc_amp = synapse.psc_amplitude
                        psc_rise_time = synapse.psc_rise_time
                        psc_decay_tau = synapse.psc_decay_tau
                        latency = synapse.latency

                    

                results[pair] = {
                'strength_no_data': no_data,
                'pre_class': pre_class,
                'post_class': post_class,
                'PSP Amplitude': psp_amp if no_data is False else float('nan'),
                'PSP Rise Time': psp_rise_time if no_data is False else float('nan'),
                'PSP Decay Tau': psp_decay_tau if no_data is False else float('nan'),
                'PSC Amplitude': psc_amp if no_data is False else float('nan'),
                'PSC Rise Time': psc_rise_time if no_data is False else float('nan'),
                'PSC Decay Tau': psc_decay_tau if no_data is False else float('nan'),
                'Latency': latency if no_data is False else float('nan'),
                }

        self.results = pd.DataFrame.from_dict(results, orient='index')

        return self.results

    def output_fields(self):

        return self.fields

    def metric_summary(self, x):
        if x.name == 'strength_no_data':
            return all(x)
        else:
            return x.mean()

    def metric_conf(self, x):
        return [-x.std(), x.std()]

    def print_element_info(self, pre_class, post_class, element, field_name=None):
        if field_name is not None:
            units = [field[1].get('units', '') for field in self.fields if field[0] == field_name][0] 
            print ("Connection type: %s -> %s" % (pre_class, post_class))    
            print ("\t Grand Average %s = %s" % (field_name, pg.siFormat(element[field_name].mean(), suffix=units)))
            print ("Connected Pairs:")
            no_qc_data = []
            for pair, value in element[field_name].iteritems():
                if pair.has_synapse is not True:
                    continue
                if np.isnan(value):
                    no_qc_data.append(pair)
                else:
                    print ("\t %s" % (pair))
                    print ("\t\t Average %s: %s" % (field_name, pg.siFormat(value, suffix=units)))
            print("\t No QC Data:")
            for pair in no_qc_data:
                print ("\t\t %s" % (pair))

    def plot_element_data(self, pre_class, post_class, element, field_name, color='g', trace_plt=None):
        val = element[field_name].mean()
        line = pg.InfiniteLine(val, pen={'color': color, 'width': 2}, movable=False)
        scatter = None
        baseline_window = int(db.default_sample_rate * 5e-3)
        values = []
        traces = []
        point_data = []
        for pair, value in element[field_name].iteritems():
            if pair.has_synapse is not True:
                continue
            if np.isnan(value):
                continue
            rsf = pair.resting_state_fit
            if rsf is not None:
                trace = rsf.vc_avg_data if field_name.startswith('PSC') else rsf.ic_avg_data
                start_time = rsf.vc_avg_data_start_time if field_name.startswith('PSC') else rsf.ic_avg_data_start_time
                latency = self.results.loc[pair]['Latency']
                if latency is None or start_time is None:
                    trace = None
                else:
                    xoffset = start_time - latency
            if trace is None:
                continue
            values.append(value)
            trace = format_trace(trace, baseline_window, x_offset=xoffset, align='psp')
            trace_item = trace_plt.plot(trace.time_values, trace.data)
            point_data.append(pair)
            trace_item.pair = pair
            trace_item.curve.setClickable(True)
            trace_item.sigClicked.connect(self.trace_plot_clicked)
            traces.append(trace)
            self.pair_items[pair.id] = [trace_item]
        y_values = pg.pseudoScatter(np.asarray(values, dtype=float), spacing=1)
        scatter = pg.ScatterPlotItem(symbol='o', brush=(color + (150,)), pen='w', size=12)
        scatter.setData(values, y_values + 10., data=point_data)
        for point in scatter.points():
            pair_id = point.data().id
            self.pair_items[pair_id].append(point)
        scatter.sigClicked.connect(self.scatter_plot_clicked)
        if len(traces) > 0:
            grand_trace = TSeriesList(traces).mean()
            name = ('%s->%s, n=%d' % (pre_class, post_class, len(traces)))
            trace_plt.plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3}, name=name)
            units = 'V' if field_name.startswith('PSP') else 'A'
            trace_plt.setXRange(-5e-3, 20e-3)
            trace_plt.setLabels(left=('', units), bottom=('Time from stimulus', 's'))
        return line, scatter

    def scatter_plot_clicked(self, scatterplt, points):
        pair = points[0].data()
        self.select_pair(pair)

    def trace_plot_clicked(self, trace):
        pair = trace.pair
        self.select_pair(pair)

    def select_pair(self, pair):
        trace, point = self.pair_items[pair.id]
        point.setBrush(pg.mkBrush('y'))
        point.setSize(15)
        trace.setPen('y', width=2)
        print('Clicked:' '%s' % pair)

    def summary(self, results, metric):
        print('')

class DynamicsAnalyzer(Analyzer):
    def __init__(self):
        Analyzer.__init__(self)
        self.name = 'dynamics'
        self.results = None
        self.group_results = None
        #self._signalHandler = ConnectivityAnalyzer.SignalHandler()
        #self.sigOutputChanged = self._signalHandler.sigOutputChanged

        self.summary_stat = {
            'dynamics_no_data': self.metric_summary,
            'Steady state plasticity': [self.metric_summary, self.metric_conf],
            'Paired pulse ratio': [self.metric_summary, self.metric_conf],
            'Recovery': [self.metric_summary, self.metric_conf],
        }
        self.summary_dtypes = {} ## dict to specify how we want to cast different summary measures
        ## looks like {('pulse_ratio_8_1_50hz', 'metric_summary'):float}
        
        self.fields = [
            ('Steady state plasticity', {'mode': 'range', 'defaults': {
                'Min': 0, 
                'Max': 2, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (255, 255, 255, 255), (255, 0, 0, 255)],
            )}}),
            ('Paired pulse ratio', {'mode': 'range', 'defaults': {
                'Min': 0, 
                'Max': 2, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (255, 255, 255, 255), (255, 0, 0, 255)],
            )}}),
            ('Recovery', {'mode': 'range', 'defaults': {
                'Min': 0, 
                'Max': 2, 
                'colormap': pg.ColorMap(
                [0, 0.5, 1.0],
                [(0, 0, 255, 255), (255, 255, 255, 255), (255, 0, 0, 255)],
            )}}),
            ('None', {}),
            ]
        self.text = {'Steady state plasticity': '{Steady state plasticity:0.2f}',
            'Paired pulse ratio': '{Paired pulse ratio:0.2f}',
            'Recovery': '{Recovery:0.2f}'}

    def invalidate_output(self):
        self.results = None
        self.group_results = None

    def metric_summary(self, x):
        if x.name == 'dynamics_no_data':
            return all(x)
        else:
            return np.nanmean(x)

    def metric_conf(self, x):
        return [-np.nanstd(x), np.nanstd(x)]

    def measure(self, pair_groups):
        """Given a list of cell pairs and a dict that groups cells together by class,
        return a structure that describes dynamics of each cell pair.
        """  
        if self.results is not None:
            return self.results

        results = OrderedDict()
        for key, class_pairs in pair_groups.items():
            pre_class, post_class = key
            
            for pair in class_pairs:
                if pair.has_synapse is False:
                    no_data = True
                    dynamics = None
                elif pair.has_synapse is True:
                    no_data = False
                    dynamics = pair.dynamics

                results[pair] = {
                'dynamics_no_data': no_data,
                'pre_class': pre_class,
                'post_class': post_class,
                'Steady state plasticity': dynamics.pulse_ratio_8_1_50hz if dynamics is not None else float('nan'),
                'Paired pulse ratio': dynamics.pulse_ratio_2_1_50hz if dynamics is not None else float('nan'),
                'Recovery': dynamics.pulse_ratio_9_1_250ms if dynamics is not None else float('nan'),
                }

        
        self.results = pd.DataFrame.from_dict(results, orient='index')
        
        return self.results

    # def group_result(self):
    #     if self.group_results is not None:
    #         return self.group_results

    #     self.group_results = self.results.groupby(['pre_class', 'post_class']).agg(self.summary_stat)
    #     return self.group_results

    def output_fields(self):
       
        return self.fields

    def print_element_info(self, pre_class, post_class, element, field_name=None):
        if field_name is not None:
            print ("Connection type: %s -> %s" % (pre_class, post_class))    
            print ("\t Grand Average %s = %s" % (field_name, element[field_name].mean()))
            print ("Connected Pairs:")
            no_qc_data = []
            for pair, value in element[field_name].iteritems():
                if pair.has_synapse is not True:
                    continue
                if np.isnan(value):
                    no_qc_data.append(pair)
                else:
                    print ("\t %s" % (pair))
                    print ("\t\t Average %s: %0.2f" % (field_name, value))
            print("\t No QC Data:")
            for pair in no_qc_data:
                print ("\t\t %s" % (pair))

    def plot_element_data(self, pre_class, post_class, element, field_name, color='g', trace_plt=None):
        trace_plt = None
        val = element[field_name].mean()
        line = pg.InfiniteLine(val, pen={'color': color, 'width': 2}, movable=False)
        scatter = None
        baseline_window = int(db.default_sample_rate * 5e-3)
        values = []
        traces = []
        point_data = []
        for pair, value in element[field_name].iteritems():
            if np.isnan(value):
                continue
            traces = []
            if trace_plt is not None:
                if rsf is not None:
                    trace = rsf.ic_avg_data
                    start_time = rsf.ic_avg_data_start_time
                    latency = pair.synapse.latency
                    if latency is not None and start_time is not None:
                        xoffset = start_time - latency
                        trace = format_trace(trace, baseline_window, x_offset=xoffset, align='psp')
                        trace_plt.plot(trace.time_values, trace.data)
                        traces.append(trace)
            values.append(value)
            y_values = pg.pseudoScatter(np.asarray(values, dtype=float), spacing=1)
            scatter = pg.ScatterPlotItem(symbol='o', brush=(color + (150,)), pen='w', size=12)
            scatter.setData(values, y_values + 10.)
            if trace_plt is not None:
                grand_trace = TSeriesList(traces).mean()
                trace_plt.plot(grand_trace.time_values, grand_trace.data, pen={'color': color, 'width': 3})
                units = 'V' if field_name.startswith('ic') else 'A'
                trace_plt.setXRange(0, 20e-3)
                trace_plt.setLabels(left=('', units), bottom=('Time from stimulus', 's'))
        return line, scatter

    def summary(self, results, metric):
        print('')


def format_trace(trace, baseline_win, x_offset=1e-3, align='spike'):
    # align can be to the pre-synaptic spike (default) or the onset of the PSP ('psp')
    baseline = float_mode(trace[0:baseline_win])
    trace = TSeries(data=(trace-baseline), sample_rate=db.default_sample_rate)
    if align == 'psp':
        trace.t0 = x_offset
    return trace

def get_all_output_fields(analyzer_list):
    data_fields = []
    text_fields = {}
    # confidence_fields = []
    for analyzer in analyzer_list:
        data_fields.extend(analyzer.output_fields())
        text_fields.update(analyzer.text)
        # confidence_fields.extend(analyzer.output_fields()['show_confidence'])

    return data_fields, text_fields

def results_scatter(results, field_name, field, plt):
    vals = [result[field_name] for result in results.values() if np.isfinite(result[field_name])]
    y, x = np.histogram(vals, bins=np.linspace(min(vals), max(vals), 10))
    plt.plot(x, y, stepMode=True, fillLevel=0, brush=(255,255,255,150))
    units = field.get('units', '')
    plt.setLabels(left='Count', bottom=(field_name, units))

def connection_probability_ci(n_connected, n_probed):
    # make sure we are consistent about how we measure connectivity confidence intervals
    return proportion_confint(n_connected, n_probed, method='beta')


def pair_was_probed(pair, excitatory):
    qc_field = 'n_%s_test_spikes' % ('ex' if excitatory else 'in')

    # arbitrary limit: we need at least N presynaptic spikes in order to consider
    # the pair "probed" for connection. Decreasing this value will decrease the number
    # of experiments included, but increase sensitivity for weaker connections
    return getattr(pair, qc_field) > 10