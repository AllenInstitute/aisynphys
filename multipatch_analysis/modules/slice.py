import os, glob, re
from datetime import datetime
from collections import OrderedDict
from acq4.util.DataManager import getDirHandle
from .. import database as db
from ..database.slice import slice_tables
from .analysis_module import AnalysisModule
from .. import config
from .. import lims
from ..util import datetime_to_timestamp


class SliceAnalysisModule(AnalysisModule):
    """Imports per-slice metadata into DB.
    """
    name = 'slice'
    dependencies = []
    
    @classmethod
    def process_job(cls, job_id):
        slices = all_slices()
        path = slices[job_id]
        dh = getDirHandle(path)
        info = dh.info()
        
        # pull some metadata from LIMS
        sid = info['specimen_ID'].strip()
        limsdata = lims.specimen_info(sid)

        quality = info.get('slice quality', None)
        try:
            quality = int(quality)
        except Exception:
            quality = None

        # Interpret slice time
        slice_time = info.get('slice time', None)
        if slice_time is not None:
            m = re.match(r'((20\d\d)-(\d{1,2})-(\d{1,2}) )?(\d+):(\d+)', slice_time.strip())
            if m is not None:
                _, year, mon, day, hh, mm = m.groups()
                if year is None:
                    date = datetime.fromtimestamp(dh.parent().info('__timestamp__'))
                    slice_time = datetime(date.year, date.month, date.day, hh, mm)
                else:
                    slice_time = datetime(year, mon, day, hh, mm)

        fields = {
            'acq_timestamp': info['__timestamp__'],
            'species': limsdata['organism'],
            'age': limsdata['age'],
            'sex': limsdata['sex'],
            'genotype': limsdata['genotype'],
            'orientation': limsdata['plane_of_section'],
            'surface': limsdata['exposed_surface'],
            'hemisphere': limsdata['hemisphere'],
            'quality': quality,
            'slice_time': slice_time,
            'slice_conditions': {},
            'lims_specimen_name': sid,
            'storage_path': dh.name(relativeTo=dh.parent().parent()),
        }

        sl = db.Slice(**fields)
        # sl.meta = {'db_timestamp': time.time()}
        
        session = db.Session(readonly=False)
        try:
            session.add(sl)
            session.commit()
        finally:
            session.close()

    @classmethod
    def initialize(cls):
        """Create space (folders, tables, etc.) for this analyzer to store its results.
        """
        raise slice_tables.create_tables()
        
    @classmethod
    def drop_jobs(cls, job_ids):
        """Remove all results previously stored for a list of job IDs.
        """
        session = db.Session(readonly=False)
        slices = session.query(db.Slice).filter(db.Slice.acq_timestamp.in_(job_ids))
        for sl in slices:
            session.delete(sl)
        session.commit()

    @classmethod
    def drop_all(cls, reinitialize=True):
        """Remove all results generated by this module.
        """
        slice_tables.drop_tables()
        if reinitialize:
            cls.initialize()        
        
    @classmethod
    def finished_jobs(cls):
        """Return an ordered dict of job IDs that have been processed by this module and
        the dates when they were processed.

        Note that some results returned may be obsolete if dependencies have changed.
        """
        session = db.Session()
        slices = session.query(db.Slice.acq_timestamp, db.Slice.time_created).all()
        session.rollback()
        return OrderedDict([(uid, datetime_to_timestamp(date)) for uid, date in slices])

    @classmethod
    def ready_jobs(self):
        slices = all_slices()
        print("found %d slices" % len(slices))
        ready = OrderedDict()
        for ts, path in slices.items():
            age = os.stat(os.path.join(path, '.index')).st_mtime
            ready[ts] = age
        print("collected timestamps")
        return ready


_all_slices = None
def all_slices():
    """Return a dict mapping {slice_timestamp: path} for all known slices.
    
    This is only generated once per running process; set _all_slices = None
    to force the list to be regenerated.
    """
    global _all_slices
    if _all_slices is not None:
        return _all_slices
    
    slice_dirs = sorted(glob.glob(os.path.join(config.synphys_data, '15234*', 'slice_*')))
    _all_slices = OrderedDict()
    for path in slice_dirs:
        dh = getDirHandle(path)
        ts = dh.info()['__timestamp__']
        _all_slices[ts] = path
        
    return _all_slices
